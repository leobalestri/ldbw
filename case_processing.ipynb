{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try setting up a class Case with properties \"corpus\", \"wordcount\", \"casenum\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class Case:\n",
    "    def __init__(self, textfile):\n",
    "        assert os.path.isfile(textfile) == True\n",
    "        # We start out with just the raw text string from the pdf\n",
    "        # We should also initialize the casenumber attribute?\n",
    "        with open(textfile, \"rb\") as file: \n",
    "            self.text = pickle.load(file)\n",
    "            self.casenumber = os.path.splitext(os.path.split(textpath)[1])[0]\n",
    "    # We should have a method for doing text cleanup and a method for \n",
    "    # count vectorization\n",
    "    def make_corpus(self):\n",
    "        '''Adds corpus attribute to the Case object by cleaning\n",
    "        the raw text string'''\n",
    "        # Make text lowercase: \n",
    "        text = self.text\n",
    "        text = text.lower()\n",
    "        # Strip all newlines: \n",
    "        text = re.sub('\\n', '', text)\n",
    "        self.corpus = text\n",
    "    def make_unigram_matrix(self):\n",
    "        '''Adds frequency-matrix-of-unigrams attribute to Case object. Requires\n",
    "        that corpus attribute already exists.'''\n",
    "        # currently redundant with ngram matrix\n",
    "        cv = CountVectorizer(input='content',stop_words = 'english')\n",
    "        freq_cv = cv.fit_transform([self.corpus])\n",
    "        freq_matrix = pd.DataFrame(freq_cv.toarray(), columns = cv.get_feature_names())\n",
    "        # Sort the words by frequency, most frequent first\n",
    "        # freq_matrix = freq_matrix.sort_values(by=0,axis=1, ascending=False)\n",
    "        # freq_matrix = freq_matrix.transpose()\n",
    "        self.unigram_matrix = freq_matrix\n",
    "    def make_ngram_matrix(self, n):\n",
    "        '''Adds frequency-matrix-of-ngrams attribute to Case object. Requires\n",
    "        that corpus attribute already exists.'''\n",
    "        cv = CountVectorizer(input='content',stop_words = 'english',strip_accents='unicode',ngram_range=(1,n))\n",
    "        freq_cv = cv.fit_transform([self.corpus])\n",
    "        freq_matrix = pd.DataFrame(freq_cv.toarray(), columns = cv.get_feature_names())\n",
    "        # Sort the words by frequency, most frequent first\n",
    "        # freq_matrix = freq_matrix.sort_values(by=0,axis=1, ascending=False)\n",
    "        # freq_matrix = freq_matrix.transpose()\n",
    "        # note: transposing matrix makes the to_string method produce\n",
    "        # a nice output, but makes indexing by ngram slightly harder?\n",
    "        self.ngram_matrix = freq_matrix\n",
    "\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leodb\\Documents\\THESIS\\ldbw\\processed_cases.txt\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(os.path.abspath(''),'processed_cases.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.abspath(''),'processed_cases.txt'), 'rb') as file:\n",
    "    processed_cases = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cases processed\n",
      "100 cases processed\n",
      "200 cases processed\n",
      "300 cases processed\n",
      "400 cases processed\n",
      "500 cases processed\n",
      "600 cases processed\n",
      "700 cases processed\n",
      "800 cases processed\n",
      "900 cases processed\n",
      "1000 cases processed\n",
      "1100 cases processed\n",
      "1200 cases processed\n",
      "1300 cases processed\n",
      "1400 cases processed\n",
      "1500 cases processed\n",
      "1600 cases processed\n",
      "1700 cases processed\n",
      "1800 cases processed\n",
      "1900 cases processed\n",
      "2000 cases processed\n",
      "2100 cases processed\n",
      "2200 cases processed\n",
      "2300 cases processed\n",
      "2400 cases processed\n",
      "2500 cases processed\n",
      "2600 cases processed\n",
      "2700 cases processed\n",
      "2800 cases processed\n",
      "2900 cases processed\n",
      "3000 cases processed\n",
      "3100 cases processed\n",
      "3200 cases processed\n",
      "3300 cases processed\n",
      "3400 cases processed\n",
      "3500 cases processed\n",
      "3600 cases processed\n",
      "3700 cases processed\n",
      "3800 cases processed\n",
      "3900 cases processed\n",
      "4000 cases processed\n",
      "4100 cases processed\n",
      "4200 cases processed\n",
      "4300 cases processed\n",
      "4400 cases processed\n",
      "4500 cases processed\n",
      "4600 cases processed\n",
      "4700 cases processed\n",
      "4800 cases processed\n",
      "4900 cases processed\n",
      "5000 cases processed\n",
      "5100 cases processed\n",
      "5200 cases processed\n",
      "5300 cases processed\n",
      "5400 cases processed\n",
      "5500 cases processed\n",
      "5600 cases processed\n",
      "5700 cases processed\n",
      "5800 cases processed\n",
      "5900 cases processed\n",
      "6000 cases processed\n",
      "6100 cases processed\n",
      "6200 cases processed\n",
      "6300 cases processed\n",
      "6400 cases processed\n",
      "6500 cases processed\n",
      "6600 cases processed\n",
      "6700 cases processed\n",
      "6800 cases processed\n",
      "6900 cases processed\n",
      "7000 cases processed\n",
      "7100 cases processed\n",
      "7200 cases processed\n",
      "7300 cases processed\n",
      "7400 cases processed\n",
      "7500 cases processed\n",
      "7600 cases processed\n",
      "7700 cases processed\n",
      "7800 cases processed\n",
      "7900 cases processed\n",
      "8000 cases processed\n",
      "8100 cases processed\n",
      "8200 cases processed\n",
      "8300 cases processed\n",
      "8400 cases processed\n",
      "8500 cases processed\n",
      "8600 cases processed\n",
      "8700 cases processed\n",
      "8800 cases processed\n",
      "8900 cases processed\n",
      "9000 cases processed\n",
      "9100 cases processed\n",
      "9200 cases processed\n",
      "9300 cases processed\n",
      "9400 cases processed\n",
      "9500 cases processed\n",
      "9600 cases processed\n",
      "9700 cases processed\n",
      "9800 cases processed\n",
      "9900 cases processed\n",
      "10000 cases processed\n",
      "10100 cases processed\n",
      "10200 cases processed\n",
      "10300 cases processed\n",
      "10400 cases processed\n",
      "10500 cases processed\n",
      "10600 cases processed\n",
      "10700 cases processed\n",
      "10800 cases processed\n",
      "10900 cases processed\n",
      "11000 cases processed\n",
      "11100 cases processed\n",
      "11200 cases processed\n",
      "11300 cases processed\n",
      "11400 cases processed\n",
      "11500 cases processed\n",
      "11600 cases processed\n",
      "11700 cases processed\n",
      "11800 cases processed\n",
      "11900 cases processed\n",
      "12000 cases processed\n",
      "12100 cases processed\n",
      "12200 cases processed\n",
      "12300 cases processed\n",
      "12400 cases processed\n",
      "12500 cases processed\n",
      "12600 cases processed\n",
      "12700 cases processed\n",
      "12800 cases processed\n",
      "12900 cases processed\n",
      "13000 cases processed\n",
      "13100 cases processed\n",
      "13200 cases processed\n",
      "13300 cases processed\n",
      "13400 cases processed\n",
      "13500 cases processed\n",
      "13600 cases processed\n",
      "13700 cases processed\n",
      "13800 cases processed\n",
      "13900 cases processed\n",
      "14000 cases processed\n",
      "14100 cases processed\n",
      "14200 cases processed\n",
      "14300 cases processed\n",
      "14400 cases processed\n",
      "14500 cases processed\n",
      "14600 cases processed\n",
      "14700 cases processed\n",
      "14800 cases processed\n",
      "14900 cases processed\n",
      "15000 cases processed\n",
      "15100 cases processed\n",
      "15200 cases processed\n",
      "15300 cases processed\n",
      "15400 cases processed\n",
      "15500 cases processed\n",
      "15600 cases processed\n",
      "15700 cases processed\n",
      "15800 cases processed\n",
      "15900 cases processed\n",
      "16000 cases processed\n",
      "16100 cases processed\n",
      "16200 cases processed\n",
      "16300 cases processed\n",
      "16400 cases processed\n",
      "16500 cases processed\n",
      "16600 cases processed\n",
      "16700 cases processed\n",
      "16800 cases processed\n",
      "16900 cases processed\n",
      "17000 cases processed\n",
      "17100 cases processed\n",
      "17200 cases processed\n",
      "17300 cases processed\n",
      "17400 cases processed\n",
      "17500 cases processed\n",
      "17600 cases processed\n",
      "17700 cases processed\n",
      "17800 cases processed\n",
      "17900 cases processed\n",
      "18000 cases processed\n",
      "18100 cases processed\n",
      "18200 cases processed\n",
      "18300 cases processed\n",
      "18400 cases processed\n",
      "18500 cases processed\n",
      "18600 cases processed\n",
      "18700 cases processed\n",
      "18800 cases processed\n",
      "18900 cases processed\n",
      "19000 cases processed\n",
      "19100 cases processed\n",
      "19200 cases processed\n",
      "19300 cases processed\n",
      "19400 cases processed\n",
      "19500 cases processed\n",
      "19600 cases processed\n",
      "19700 cases processed\n",
      "19800 cases processed\n",
      "19900 cases processed\n",
      "20000 cases processed\n",
      "20100 cases processed\n",
      "20200 cases processed\n",
      "20300 cases processed\n",
      "20400 cases processed\n",
      "20500 cases processed\n",
      "20600 cases processed\n",
      "20700 cases processed\n",
      "20800 cases processed\n",
      "20900 cases processed\n",
      "21000 cases processed\n",
      "21100 cases processed\n",
      "21200 cases processed\n",
      "21300 cases processed\n",
      "21400 cases processed\n",
      "21500 cases processed\n",
      "21600 cases processed\n",
      "21700 cases processed\n",
      "21800 cases processed\n",
      "21900 cases processed\n",
      "22000 cases processed\n",
      "22100 cases processed\n",
      "22200 cases processed\n",
      "22300 cases processed\n",
      "22400 cases processed\n",
      "22500 cases processed\n",
      "22600 cases processed\n",
      "22700 cases processed\n",
      "22800 cases processed\n"
     ]
    }
   ],
   "source": [
    "la_cases = []\n",
    "maybe_cases = []\n",
    "location_flag = []\n",
    "failed_cases = []\n",
    "i = 0\n",
    "for case in processed_cases: \n",
    "    if i % 100 == 0: \n",
    "        print('%d cases processed' % i)\n",
    "    try: \n",
    "        cols = case.ngram_matrix.columns\n",
    "        if 'los angeles super' in cols or 'los angeles county super' in cols:\n",
    "            la_cases.append(case)\n",
    "        elif 'los angeles county' in cols:\n",
    "            maybe_cases.append(case)\n",
    "        else:\n",
    "            location_flag.append(case)\n",
    "    except (KeyboardInterrupt,SystemExit): \n",
    "        raise\n",
    "    except:\n",
    "        failed_cases.append(case)\n",
    "        print('Failed case at %d' % case.casenumber)\n",
    "        continue\n",
    "    finally: \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cases processed\n",
      "100 cases processed\n",
      "200 cases processed\n",
      "300 cases processed\n",
      "400 cases processed\n",
      "500 cases processed\n",
      "600 cases processed\n",
      "700 cases processed\n",
      "800 cases processed\n",
      "900 cases processed\n",
      "1000 cases processed\n",
      "1100 cases processed\n",
      "1200 cases processed\n",
      "1300 cases processed\n",
      "1400 cases processed\n",
      "1500 cases processed\n",
      "1600 cases processed\n",
      "1700 cases processed\n",
      "1800 cases processed\n",
      "1900 cases processed\n",
      "2000 cases processed\n",
      "2100 cases processed\n",
      "2200 cases processed\n",
      "2300 cases processed\n",
      "2400 cases processed\n",
      "2500 cases processed\n",
      "2600 cases processed\n",
      "2700 cases processed\n",
      "2800 cases processed\n",
      "2900 cases processed\n",
      "3000 cases processed\n",
      "3100 cases processed\n",
      "3200 cases processed\n",
      "3300 cases processed\n",
      "3400 cases processed\n",
      "3500 cases processed\n",
      "3600 cases processed\n",
      "3700 cases processed\n",
      "3800 cases processed\n",
      "3900 cases processed\n",
      "4000 cases processed\n",
      "4100 cases processed\n",
      "4200 cases processed\n",
      "4300 cases processed\n",
      "4400 cases processed\n",
      "4500 cases processed\n",
      "4600 cases processed\n",
      "4700 cases processed\n",
      "4800 cases processed\n",
      "4900 cases processed\n",
      "5000 cases processed\n",
      "5100 cases processed\n",
      "5200 cases processed\n",
      "5300 cases processed\n",
      "5400 cases processed\n",
      "5500 cases processed\n",
      "5600 cases processed\n",
      "5700 cases processed\n",
      "5800 cases processed\n",
      "5900 cases processed\n",
      "6000 cases processed\n",
      "6100 cases processed\n",
      "6200 cases processed\n",
      "6300 cases processed\n",
      "6400 cases processed\n",
      "6500 cases processed\n",
      "6600 cases processed\n",
      "6700 cases processed\n",
      "6800 cases processed\n",
      "6900 cases processed\n",
      "7000 cases processed\n",
      "7100 cases processed\n",
      "7200 cases processed\n",
      "7300 cases processed\n",
      "7400 cases processed\n",
      "7500 cases processed\n",
      "7600 cases processed\n",
      "7700 cases processed\n",
      "7800 cases processed\n",
      "7900 cases processed\n",
      "8000 cases processed\n",
      "8100 cases processed\n",
      "8200 cases processed\n",
      "8300 cases processed\n",
      "8400 cases processed\n",
      "8500 cases processed\n",
      "8600 cases processed\n",
      "8700 cases processed\n",
      "8800 cases processed\n",
      "8900 cases processed\n",
      "9000 cases processed\n",
      "9100 cases processed\n",
      "9200 cases processed\n",
      "9300 cases processed\n",
      "9400 cases processed\n",
      "9500 cases processed\n",
      "9600 cases processed\n",
      "9700 cases processed\n",
      "9800 cases processed\n",
      "9900 cases processed\n",
      "10000 cases processed\n",
      "10100 cases processed\n",
      "10200 cases processed\n",
      "10300 cases processed\n",
      "10400 cases processed\n",
      "10500 cases processed\n",
      "10600 cases processed\n",
      "10700 cases processed\n",
      "10800 cases processed\n",
      "10900 cases processed\n",
      "11000 cases processed\n",
      "11100 cases processed\n",
      "11200 cases processed\n",
      "11300 cases processed\n",
      "11400 cases processed\n",
      "11500 cases processed\n",
      "11600 cases processed\n",
      "11700 cases processed\n",
      "11800 cases processed\n",
      "11900 cases processed\n",
      "12000 cases processed\n",
      "12100 cases processed\n",
      "12200 cases processed\n",
      "12300 cases processed\n",
      "12400 cases processed\n",
      "12500 cases processed\n",
      "12600 cases processed\n",
      "12700 cases processed\n",
      "12800 cases processed\n",
      "12900 cases processed\n",
      "13000 cases processed\n",
      "13100 cases processed\n",
      "13200 cases processed\n",
      "13300 cases processed\n",
      "13400 cases processed\n",
      "13500 cases processed\n",
      "13600 cases processed\n",
      "13700 cases processed\n",
      "13800 cases processed\n",
      "13900 cases processed\n",
      "14000 cases processed\n",
      "14100 cases processed\n",
      "14200 cases processed\n",
      "14300 cases processed\n",
      "14400 cases processed\n",
      "14500 cases processed\n",
      "14600 cases processed\n",
      "14700 cases processed\n",
      "14800 cases processed\n",
      "14900 cases processed\n",
      "15000 cases processed\n",
      "15100 cases processed\n",
      "15200 cases processed\n",
      "15300 cases processed\n",
      "15400 cases processed\n",
      "15500 cases processed\n",
      "15600 cases processed\n",
      "15700 cases processed\n",
      "15800 cases processed\n",
      "15900 cases processed\n",
      "16000 cases processed\n",
      "16100 cases processed\n",
      "16200 cases processed\n",
      "16300 cases processed\n",
      "16400 cases processed\n",
      "16500 cases processed\n",
      "16600 cases processed\n",
      "16700 cases processed\n",
      "16800 cases processed\n",
      "16900 cases processed\n",
      "17000 cases processed\n",
      "17100 cases processed\n",
      "17200 cases processed\n",
      "17300 cases processed\n",
      "17400 cases processed\n",
      "17500 cases processed\n",
      "17600 cases processed\n",
      "17700 cases processed\n",
      "17800 cases processed\n",
      "17900 cases processed\n",
      "18000 cases processed\n",
      "18100 cases processed\n",
      "18200 cases processed\n",
      "18300 cases processed\n",
      "18400 cases processed\n",
      "18500 cases processed\n",
      "18600 cases processed\n",
      "18700 cases processed\n",
      "18800 cases processed\n",
      "18900 cases processed\n",
      "19000 cases processed\n",
      "19100 cases processed\n",
      "19200 cases processed\n"
     ]
    }
   ],
   "source": [
    "la_felonies = []\n",
    "maybe_felonies = []\n",
    "felony_flag = []\n",
    "failed_cases = []\n",
    "i = 0\n",
    "for case in la_cases: \n",
    "    if i % 100 == 0: \n",
    "        print('%d cases processed' % i)\n",
    "    try: \n",
    "        m = case.ngram_matrix\n",
    "        if len(m.filter(regex='super ct no [a-z]a\\d{6}').columns)!=0 or len(m.filter(regex='super ct nos [a-z]a\\d{6}').columns)!=0:\n",
    "            la_felonies.append(case)\n",
    "        elif len(m.filter(regex='[a-z]a\\d{6}').columns)!=0:\n",
    "            maybe_felonies.append(case)\n",
    "        else:\n",
    "            felony_flag.append(case)\n",
    "    except (KeyboardInterrupt,SystemExit): \n",
    "        raise\n",
    "    except:\n",
    "        failed_cases.append(case)\n",
    "        print('Failed case at %d' % case.casenumber)\n",
    "        continue\n",
    "    finally: \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19290"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(la_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1229"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(maybe_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "8343\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n"
     ]
    }
   ],
   "source": [
    "print(len(la_felonies))\n",
    "print(len(maybe_felonies))\n",
    "felonies_second_pass = []\n",
    "hhh = []\n",
    "i = 0\n",
    "for f in maybe_felonies[1001:]: \n",
    "    if len(m.filter(regex='super ct [a-z]a\\d{6}').columns) == 0:\n",
    "        hhh.append(f)\n",
    "    else: \n",
    "        felonies_second_pass.append(f)\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(maybe_felonies)\n",
    "probable_felonies = la_felonies + maybe_felonies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 8), match='ba333959'>\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "t1 = 'ba333959'\n",
    "t2 = '0a345909'\n",
    "t3 = 'bb220020'\n",
    "t4 = 'ba242'\n",
    "\n",
    "\n",
    "print(re.search('[a-z]a\\d{6}', t1))\n",
    "print(re.search('[a-z]a\\d{6}', t2))\n",
    "print(re.search('[a-z]a\\d{6}', t3))\n",
    "print(re.search('[a-z]a\\d{6}', t4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('la_felonies', 'wb') as file:\n",
    "    pickle.dump(probable_felonies, file)\n",
    "with open('la_cases', 'wb') as file: \n",
    "    pickle.dump(la_cases, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=la_cases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-31681684a447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngram_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[a-z]a\\d{6}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RangeIndex' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "c.ngram_matrix.index.contains('[a-z]a\\d{6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(c.ngram_matrix.filter(regex='[a-z]a\\d{6}').columns)==0)\n",
    "print(len(c.ngram_matrix.filter(regex='[a-z]a\\d{10}').columns)==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we probably want to have a dataframe that has the case number as the index and columns like \"THREE_STRIKES\", \"APPOINTED_ATTORNEY\", \"WEAPONS_ENHANCEMENT\", \"PROSECUTOR\", \"DATE_FILED\", etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F403C76088&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001EE683CAF88&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F3FBD90448&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F3FDE35148&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40AF76BC8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40B948C88&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40D01F3C8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40F25E6C8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F400223BC8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F411DBD588&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F414225D88&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40474EC88&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F4064941C8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F409713508&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40D29D5C8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F40FB17148&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F411E55D88&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F3F20C1F08&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001F3F2BFD148&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;__main__.Case object at 0x000001EE6835E708&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0\n",
       "0   <__main__.Case object at 0x000001F403C76088>\n",
       "1   <__main__.Case object at 0x000001EE683CAF88>\n",
       "2   <__main__.Case object at 0x000001F3FBD90448>\n",
       "3   <__main__.Case object at 0x000001F3FDE35148>\n",
       "4   <__main__.Case object at 0x000001F40AF76BC8>\n",
       "5   <__main__.Case object at 0x000001F40B948C88>\n",
       "6   <__main__.Case object at 0x000001F40D01F3C8>\n",
       "7   <__main__.Case object at 0x000001F40F25E6C8>\n",
       "8   <__main__.Case object at 0x000001F400223BC8>\n",
       "9   <__main__.Case object at 0x000001F411DBD588>\n",
       "10  <__main__.Case object at 0x000001F414225D88>\n",
       "11  <__main__.Case object at 0x000001F40474EC88>\n",
       "12  <__main__.Case object at 0x000001F4064941C8>\n",
       "13  <__main__.Case object at 0x000001F409713508>\n",
       "14  <__main__.Case object at 0x000001F40D29D5C8>\n",
       "15  <__main__.Case object at 0x000001F40FB17148>\n",
       "16  <__main__.Case object at 0x000001F411E55D88>\n",
       "17  <__main__.Case object at 0x000001F3F20C1F08>\n",
       "18  <__main__.Case object at 0x000001F3F2BFD148>\n",
       "19  <__main__.Case object at 0x000001EE6835E708>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = la_cases[0:20]\n",
    "qd = pd.DataFrame(q)\n",
    "qd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go too much farther, we should make this a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_use = ['APPEALS_CASE_NUMBER', 'CORPUS', 'NGRAM_MATRIX']\n",
    "lst = []\n",
    "for case in probable_felonies:\n",
    "    lst.append([case.casenumber, case.corpus, case.ngram_matrix])\n",
    "df = pd.DataFrame(lst, columns=columns_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPEALS_CASE_NUMBER</th>\n",
       "      <th>CORPUS</th>\n",
       "      <th>NGRAM_MATRIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B213582</td>\n",
       "      <td>filed 4/2/12  p. v. khrayan ca2/2 not to be pu...</td>\n",
       "      <td>00  00 10  00 10 00  00 10 00 detective  00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B226851</td>\n",
       "      <td>filed 7/31/12  p. v. scott ca2/7 not to be p...</td>\n",
       "      <td>100  100 feet  100 feet aqueduct  100 feet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B227717</td>\n",
       "      <td>filed 3/20/12  p. v. frazier ca2/5 not to be p...</td>\n",
       "      <td>000  000 past  000 past years  000 past yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B228643</td>\n",
       "      <td>filed 5/21/12  p. v. mcclelland ca2/7 not to b...</td>\n",
       "      <td>000  000 cash  000 cash days  000 cash days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B231195</td>\n",
       "      <td>filed 4/24/12  p. v. rodriguez ca2/7  not to b...</td>\n",
       "      <td>10  10 2010  10 2010 rodriguez  10 2010 rod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8469</th>\n",
       "      <td>B299414</td>\n",
       "      <td>filed 12/4/19  p. v. moore ca2/1 not to be pub...</td>\n",
       "      <td>1115  1115 court  1115 court appeal  1115 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8470</th>\n",
       "      <td>B299419</td>\n",
       "      <td>filed 1/17/20  p. v. bracamonte ca2/8 not to b...</td>\n",
       "      <td>106  106 wende  106 wende supra  106 wende ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8471</th>\n",
       "      <td>B299427</td>\n",
       "      <td>filed 12/10/19  p. v. cole ca2/1 not to be pub...</td>\n",
       "      <td>10  10 19  10 19 cole  10 19 cole ca2  10 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>B300189</td>\n",
       "      <td>filed 1/14/20  p. v. keith ca2/3 not to be p...</td>\n",
       "      <td>10  10 2019  10 2019 keith  10 2019 keith d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>B300885</td>\n",
       "      <td>filed 12/24/19  in re chamberlain ca2/4 not to...</td>\n",
       "      <td>10  10 348  10 348 352353  10 348 352353 ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8474 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     APPEALS_CASE_NUMBER                                             CORPUS  \\\n",
       "0                B213582  filed 4/2/12  p. v. khrayan ca2/2 not to be pu...   \n",
       "1                B226851    filed 7/31/12  p. v. scott ca2/7 not to be p...   \n",
       "2                B227717  filed 3/20/12  p. v. frazier ca2/5 not to be p...   \n",
       "3                B228643  filed 5/21/12  p. v. mcclelland ca2/7 not to b...   \n",
       "4                B231195  filed 4/24/12  p. v. rodriguez ca2/7  not to b...   \n",
       "...                  ...                                                ...   \n",
       "8469             B299414  filed 12/4/19  p. v. moore ca2/1 not to be pub...   \n",
       "8470             B299419  filed 1/17/20  p. v. bracamonte ca2/8 not to b...   \n",
       "8471             B299427  filed 12/10/19  p. v. cole ca2/1 not to be pub...   \n",
       "8472             B300189    filed 1/14/20  p. v. keith ca2/3 not to be p...   \n",
       "8473             B300885  filed 12/24/19  in re chamberlain ca2/4 not to...   \n",
       "\n",
       "                                           NGRAM_MATRIX  \n",
       "0        00  00 10  00 10 00  00 10 00 detective  00...  \n",
       "1        100  100 feet  100 feet aqueduct  100 feet ...  \n",
       "2        000  000 past  000 past years  000 past yea...  \n",
       "3        000  000 cash  000 cash days  000 cash days...  \n",
       "4        10  10 2010  10 2010 rodriguez  10 2010 rod...  \n",
       "...                                                 ...  \n",
       "8469     1115  1115 court  1115 court appeal  1115 c...  \n",
       "8470     106  106 wende  106 wende supra  106 wende ...  \n",
       "8471     10  10 19  10 19 cole  10 19 cole ca2  10 1...  \n",
       "8472     10  10 2019  10 2019 keith  10 2019 keith d...  \n",
       "8473     10  10 348  10 348 352353  10 348 352353 ga...  \n",
       "\n",
       "[8474 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('felonies_dataframe', 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>00 10</th>\n",
       "      <th>00 10 00</th>\n",
       "      <th>00 10 00 detective</th>\n",
       "      <th>00 10 00 detective currie</th>\n",
       "      <th>00 detective</th>\n",
       "      <th>00 detective currie</th>\n",
       "      <th>00 detective currie interviewed</th>\n",
       "      <th>00 detective currie interviewed gina</th>\n",
       "      <th>00 january</th>\n",
       "      <th>...</th>\n",
       "      <th>zapien 1993 cal 4th 929</th>\n",
       "      <th>zapien supra</th>\n",
       "      <th>zapien supra cal</th>\n",
       "      <th>zapien supra cal 4th</th>\n",
       "      <th>zapien supra cal 4th 964</th>\n",
       "      <th>zapienapparent</th>\n",
       "      <th>zapienapparent evidence</th>\n",
       "      <th>zapienapparent evidence destroyed</th>\n",
       "      <th>zapienapparent evidence destroyed nature</th>\n",
       "      <th>zapienapparent evidence destroyed nature defendant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B213582</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 17265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00  00 10  00 10 00  00 10 00 detective  00 10 00 detective currie  \\\n",
       "B213582   3      1         1                   1                          1   \n",
       "\n",
       "         00 detective  00 detective currie  00 detective currie interviewed  \\\n",
       "B213582             1                    1                                1   \n",
       "\n",
       "         00 detective currie interviewed gina  00 january  ...  \\\n",
       "B213582                                     1           1  ...   \n",
       "\n",
       "         zapien 1993 cal 4th 929  zapien supra  zapien supra cal  \\\n",
       "B213582                        1             2                 2   \n",
       "\n",
       "         zapien supra cal 4th  zapien supra cal 4th 964  zapienapparent  \\\n",
       "B213582                     2                         2               1   \n",
       "\n",
       "         zapienapparent evidence  zapienapparent evidence destroyed  \\\n",
       "B213582                        1                                  1   \n",
       "\n",
       "         zapienapparent evidence destroyed nature  \\\n",
       "B213582                                         1   \n",
       "\n",
       "         zapienapparent evidence destroyed nature defendant  \n",
       "B213582                                                  1   \n",
       "\n",
       "[1 rows x 17265 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = probable_felonies[0].ngram_matrix\n",
    "last = c.index[-1]\n",
    "c = c.rename(index={last: probable_felonies[0].casenumber})\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'concat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-4ef1ee48db6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mlst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmaster_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaster_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mmaster_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'concat'"
     ]
    }
   ],
   "source": [
    "master_table = pd.DataFrame\n",
    "lst = []\n",
    "for case in probable_felonies: \n",
    "    df = case.ngram_matrix\n",
    "    last = df.index[-1]\n",
    "    df = df.rename(index={last: case.casenumber})\n",
    "    lst.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = pd.concat(lst, axis=1, sort=False)\n",
    "master_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('master_table', 'wb') as file: \n",
    "    pickle.dump(master_table, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
